{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "toc: true\n",
    "comments: true\n",
    "layout: post\n",
    "title: Computing Bias\n",
    "description: College Board Big Idea 5.3 Computing Bias Student Lesson\n",
    "type: hacks\n",
    "courses: { compsci: {week: 15} }\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Biases Reflected As Computer Biases\n",
    "\n",
    "**Bias**: prejudice in favor of or against a thing, person, or group\n",
    "\n",
    "## What is \"computer bias\"?\n",
    "The existence of prejudiced outcomes in the decisions or predictions made by computer systems/algorithms. Bias can be implemented into algorithms because of human biases being intentionally inserted or because of the data utilized being biased.\n",
    "\n",
    "**Explicit Data:**\n",
    "Information directly provided by user.\n",
    "\n",
    "**Implicit Data:**\n",
    "Infomration that can inferred from explicit data. \n",
    "\n",
    "Based on either explicit/implicit data that has been used to train an algorithm, whether intentionally introduced or during the process of training data generation, bias can be created.\n",
    "\n",
    "<img src=\"https://static01.nyt.com/images/2020/03/10/multimedia/ihw-nudgebias/ihw-nudgebias-mediumSquareAt3X.jpg\" width=\"450\" length=\"450\">\n",
    "\n",
    "A notable example of this is seen in Netflix, where there are is a human factor that drives bias: Netflix exclusives are placed ahead (a show that is a Netflix exclusive means that users will be more likely to stay with Netflix). The bias in this case is Netflix's prioritzation towards Netflix-produced shows.\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*8BtlgpxyjOPaLZXO6pVD0Q.jpeg\" width=\"700\" length=\"394\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hack 1: \n",
    "What is another example of a human bias being implemented into an algorithm? \n",
    "> Answer: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing Bias\n",
    "Programmers should take action to reduce bias in algorithms used for computing innovations as a way of combating existing human biases. Softwares need to be unbiased, consider all everything, and reject human bias.\n",
    "\n",
    "Things to consider when developing programs:\n",
    "- What are potential sources of bias?\n",
    "- Is your program enhancing or intentionally excluding?\n",
    "- Are you receiving feedback from a widespread group of people?\n",
    "- How could people who differ from you use your developments?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hack 2: \n",
    "What is another way a programmer can reduce bias in their softwares?\n",
    "> Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of Bias in Software Development\n",
    "Biases can be embedded at all levels of software development.\n",
    "\n",
    "It can be intentional or unintentional. Some software development are made for a certain market and ensure that people of certain places or demographics can use them easily. However, this doesn't mean that they are trying to exclude.  \n",
    "\n",
    "Examples: \n",
    "\n",
    "**Intentional**: \n",
    "- Games could be geared towards a certain age range (Talking Tom vs Valorant)\n",
    "    - Game concepts\n",
    "    - Music\n",
    "    - Visuals\n",
    "\n",
    "<img src=\"https://is1-ssl.mzstatic.com/image/thumb/PurpleSource126/v4/fb/63/3e/fb633e5e-920b-aab4-3b5e-770edca48ca8/011eb6d7-683f-4586-8794-fa67e2dfc403_screenshot_ipad_en-US_6577036012549030604.jpg/643x0w.jpg\" width=\"429\" length=\"572\">\n",
    "<img src=\"https://www.pcgameshardware.de/screenshots/1280x/2020/03/Reveal_Window_VALORANT-pcgh.jpg\" width=\"640\" length=\"360\">\n",
    "\n",
    "- WeChat and KakaoTalk\n",
    "    - Almost everyone in China uses WeChat\n",
    "    - KakaoTalk is the Korean version\n",
    "\n",
    "**Unintentional**: \n",
    "- Social media, Facebook vs. instagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hack 3:\n",
    "What are some other examples of intentional and/or unintentional bias in innovations (games, social media, technology, etc.)?\n",
    "> Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "### Question 1: \n",
    "Define \"computer bias\" in your own words and explain how it can result from intentional or unintentional factors in software development. Give a brief example of this. Explain how programmers can actively work to reduce bias in their algorithms?\n",
    "\n",
    "> Answer:\n",
    "\n",
    "### Question 2:\n",
    "Briefly describe the two types of bias in software development and provide examples from the gaming industry and social media platforms. How might biases in software design affect user engagement and experiences?\n",
    "\n",
    "> Answer:\n",
    "\n",
    "### Question 1:\n",
    "Define \"computer bias\" in your own words and explain how it can result from intentional or unintentional factors in software development. Give a brief example of this. Explain how programmers can actively work to reduce bias in their algorithms?\n",
    "> Answer: Computer bias refers to unfair or discriminatory outcomes in algorithms. To mitigate computer bias, it is crucial to regularly update and diversify training data, ensuring it reflects a broad spectrum of demographics. Additionally, implementing transparent and accountable algorithms, along with continuous monitoring and evaluation, can help identify and address biased patterns in machine learning models.\n",
    "### Question 2:\n",
    "Briefly describe the two types of bias in software development and provide examples from the gaming industry and social media platforms. How might biases in software design affect user engagement and experiences?\n",
    "> Answer: In programming, intentional bias may occur when a developer purposefully incorporates discriminatory features or rules into a software system. This can manifest in biased decision-making or unequal treatment based on certain characteristics, potentially leading to inequities in user experience or outcomes.\n",
    "Unintentional bias in programming refers to the inadvertent introduction of discriminatory elements due to oversight, lack of awareness, or unintentional consequences during the coding process. This can result from using biased datasets, relying on flawed assumptions, or not considering the diverse perspectives of end-users.\n",
    "The impact of intentional or unintentional bias in programming can lead to unfair treatment, unequal access, and perpetuation of societal inequalities within software applications. It underscores the importance of developers being vigilant about recognizing and addressing biases to ensure that their programs are equitable and inclusive."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
